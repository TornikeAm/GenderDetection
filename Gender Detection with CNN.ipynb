{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import imgaug as ia\n",
    "# import imgaug.augmenters as iaa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ia.seed(1)\n",
    "from imgaug import augmenters as iaa \n",
    "import re\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import cv2 as cv\n",
    "import os\n",
    "import scipy.io\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move wiki.mat file to current directory\n",
    "mv wiki/wiki.mat ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Mat File TO csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_tocsv():\n",
    "    mat = scipy.io.loadmat('wiki.mat')\n",
    "    instances = mat['wiki'][0][0][0].shape[1]\n",
    "    columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\",\\\n",
    "                \"name\", \"face_location\", \"face_score\", \"second_face_score\"]\n",
    "    df = pd.DataFrame(index = range(0,instances), columns = columns)\n",
    "    for i in mat:\n",
    "        if i == \"wiki\":\n",
    "            current_array = mat[i][0][0]\n",
    "            for j in range(len(current_array)):\n",
    "                df[columns[j]] = pd.DataFrame(current_array[j][0])\n",
    "    return df\n",
    "\n",
    "df=convert_mat_tocsv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "aug = iaa.SomeOf(2, [\n",
    "    iaa.Affine(rotate=45),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.2*255),\n",
    "    iaa.Add(50, per_channel=True),\n",
    "    iaa.Sharpen(alpha=0.5),\n",
    "    iaa.AddToHueAndSaturation((-60, 60)),\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path For Image Augmentation\n",
    "path_for_aug='wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are Augmenting Images to Avoid Overfitting (Data Has Nearly 49000 MAle Pictures and 12000 Female Pictures)\n",
    "#This Section Is Really Time Consuming!!\n",
    "def AugmentImages(aug_Path,augmentator):\n",
    "    #Creating New Dataframe With Same Columns of Original.\n",
    "    dff=pd.DataFrame(columns=[\"dob\", \"photo_taken\", \"full_path\", \"gender\",\\\n",
    "                  \"name\", \"face_location\", \"face_score\", \"second_face_score\"])\n",
    "    #Since The Dataframe shows that Dataset is unbalanced we need to augment only The Images that have 0.0 gender(Female Images)\n",
    "    for index,image in enumerate(df['full_path']):\n",
    "        #getting The Gender of Image\n",
    "        gend=df.loc[df['full_path'] == image[0], 'gender'].iloc[0]\n",
    "        #if Gender is Female\n",
    "        if (gend==0.0).any():\n",
    "            #Augment The image 3 times\n",
    "            for i in range(3):\n",
    "                try:\n",
    "                    #get The Path of The image\n",
    "                    img_path=os.path.join(aug_Path,image[0])\n",
    "                    #Read Image\n",
    "                    img=imageio.imread(img_path)\n",
    "                    #augment it With Allready Chosen augmentation Types\n",
    "                    aug=augmentator(image=img)\n",
    "                    #get The Folder OF the image\n",
    "                    folder=(img_path).split('/',4)[1]\n",
    "                    #get The name of the image\n",
    "                    imagename = os.path.basename(img_path)\n",
    "                    #add 'aug' in the middle of the name(its Arbitrary, i Just added it in the middle)\n",
    "                    aug_name=f\"{imagename[:4]}aug{imagename[:-4]}\"\n",
    "                    #write augmented Images in The same folder \n",
    "                    cv.imwrite(f'wiki/{folder}/{aug_name}{index}{i}.jpg',aug)\n",
    "                    #Get All column Values of the image\n",
    "                    gender=df.loc[df['full_path'] == image[0], 'gender'].iloc[0]\n",
    "                    face_score=df.loc[df['full_path'] == image[0], 'face_score'].iloc[0]\n",
    "                    second_face_score=df.loc[df['full_path'] == image[0], 'second_face_score'].iloc[0]\n",
    "                    name=df.loc[df['full_path'] == image[0], 'name'].iloc[0]\n",
    "                    photo_taken=df.loc[df['full_path'] == image[0], 'photo_taken'].iloc[0]\n",
    "                    dob=df.loc[df['full_path'] == image[0], 'dob'].iloc[0]\n",
    "                    face_location=df.loc[df['full_path'] == image[0], 'face_location'].iloc[0]\n",
    "                    #add The vales to new Dataframe\n",
    "                    dff.loc[int(f'{index}{i}')]=[dob,photo_taken,[f'{folder}/{aug_name}{index}{i}.jpg'],gender,name,face_location,face_score,second_face_score]\n",
    "                except:\n",
    "                    continue  \n",
    "\n",
    "    return dff\n",
    "\n",
    "img=augment(path_for_aug,aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate Old And New Dataframe with new images, Set ignore_index To True to reset all the indices from zero to length of the images\n",
    "all_df=pd.concat([df,img],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Face Directory To Save Cropped Faces\n",
    "dirName = 'Face'\n",
    "try:\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Images(Dataset):\n",
    "    def __init__(self,path,df,path1,transform=None):\n",
    "        self.path=path\n",
    "        self.df=df\n",
    "        self.path1=path1\n",
    "        self.transform=transform\n",
    "        #run in Once\n",
    "        self.export()\n",
    "\n",
    "    #Crop Faces\n",
    "    def cropFace(self,image,imgname):\n",
    "        try:\n",
    "            #Crop Faces with Haaras cascade\n",
    "            facedata = \"haarcascade_frontalface_default.xml\"\n",
    "            cascade = cv.CascadeClassifier(facedata)\n",
    "            img = cv.imread(image)\n",
    "            minisize = (img.shape[1],img.shape[0])\n",
    "            miniframe = cv.resize(img, minisize)\n",
    "            faces = cascade.detectMultiScale(miniframe)\n",
    "            for f in faces:\n",
    "                x, y, w, h = [ v for v in f ]\n",
    "                cv.rectangle(img, (x,y), (x+w,y+h), (255,0,0))\n",
    "\n",
    "                sub_face = img[y:y+h, x:x+w]\n",
    "                face_file_name = f\"Face/{imgname}.jpg\"\n",
    "                cv.imwrite(face_file_name, sub_face)\n",
    "        except:\n",
    "            del image\n",
    "\n",
    "    #Export Cropped Faces To Face Directory \n",
    "    def export(self):\n",
    "        images = glob.glob(self.path)\n",
    "        for imgpath in images[0:]:\n",
    "            imagename = os.path.basename(imgpath)\n",
    "            imgname = os.path.splitext(imagename)[0]\n",
    "            self.cropFace(imgpath, imgname)\n",
    "    \n",
    "        \n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #get the image with y_label Wich is Gender in this Case\n",
    "        try:\n",
    "            img_path=os.path.join(self.path1,self.df.iloc[index,2][0].split('/',1)[1])\n",
    "            global img\n",
    "            img=cv.imread(img_path,cv.IMREAD_GRAYSCALE)\n",
    "            global y_label\n",
    "            y_label=torch.tensor(int(self.df.iloc[index,3]))\n",
    "            #Resize Images SInce they have to be Same Sizes\n",
    "            img=cv.resize(img,(132,132))\n",
    "            img=torch.tensor(img)\n",
    "        except:\n",
    "            img=torch.tensor(np.ones((132,132)))      \n",
    "    \n",
    "        return (img.float(),y_label)\n",
    "\n",
    "\n",
    "    #returns The Quantity Of Images\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "\n",
    "dataset=Images(path,all_df,path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Dataset Into Train,validation And Test Sets\n",
    "train_set,val_set,test_set=torch.utils.data.random_split(dataset,[int(len(dataset)*0.7),int(len(dataset)*0.15),int(len(dataset)*0.15+1)])\n",
    "train_loader=DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_set,batch_size=64,shuffle=False)\n",
    "val_loader=DataLoader(val_set,batch_size=64,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnImages(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5,1)\n",
    "        self.conv2=nn.Conv2d(6,16,5,1)\n",
    "        self.conv3=nn.Conv2d(16,10,5,1)\n",
    "        self.conv4=nn.Conv2d(10,6,5,1)\n",
    "        self.fc1=nn.Linear(6*4*4,84)\n",
    "        self.fc2=nn.Linear(84,10)\n",
    "        self.fc3=nn.Linear(10,2)\n",
    "\n",
    "  \n",
    "\n",
    "    def forward(self,X):\n",
    "        X=X.unsqueeze(1)\n",
    "        X=F.relu(self.conv1(X))\n",
    "        X=F.max_pool2d(X,2,2)\n",
    "        X=F.relu(self.conv2(X))\n",
    "        X=F.max_pool2d(X,2,2)\n",
    "        X=F.relu(self.conv3(X))\n",
    "        X=F.max_pool2d(X,2,2)\n",
    "        X=F.relu(self.conv4(X))\n",
    "        X=F.max_pool2d(X,2,2)\n",
    "        X=X.view(-1,6*4*4)\n",
    "        X=F.relu(self.fc1(X))\n",
    "        X=F.relu(self.fc2(X))\n",
    "        X=self.fc3(X)\n",
    "        return F.log_softmax(X,dim=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model=CnnImages()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I Chose CrossEntropyLoss Because i think its Optimal for binary classification, but you can try Other Loss Functions too\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "#If you Lower The Learning Rate i would recommend To increase Epochs, in opposite, if you raise learning rate i would recommend to lower the epochs\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time \n",
    "start_time=time.time()\n",
    "\n",
    "epochs=20\n",
    "test_losses=[]\n",
    "train_losses=[]\n",
    "train_correct=[]\n",
    "test_correct=[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trn_corr=0\n",
    "    tst_corr=0\n",
    "\n",
    "    for b,(X_train,y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "\n",
    "        y_pred=model(X_train)\n",
    "        loss=criterion(y_pred,y_train)\n",
    "        #get the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "\n",
    "        #update Parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if b%1000 == 0:\n",
    "            print(f'epoch: {i:2} loss: {loss.item():10.8f}  \\\n",
    "    accuracy: {trn_corr.item()*100/(64*b):7.3f}%')\n",
    "\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b,(X_test,y_test) in enumerate(val_loader):\n",
    "            y_val=model(X_test)\n",
    "            predicted=torch.max(y_val.data,1)[1]\n",
    "            tst_corr+=(predicted==y_test).sum()\n",
    "        loss=criterion(y_val,y_test)\n",
    "        test_losses.append(loss)\n",
    "        test_correct.append(tst_corr)\n",
    "\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([t/64 for t in train_correct], label='training accuracy')\n",
    "plt.plot([t/64 for t in test_correct],label='test Accuracy')\n",
    "plt.title('Accuracy at the end of each epoch')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Image index To test Different Images\n",
    "class_names=['female','male']\n",
    "image_index=0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[image_index][0].view(1,1,132,132)).argmax()\n",
    "    \n",
    "class_names[new_pred.item()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
